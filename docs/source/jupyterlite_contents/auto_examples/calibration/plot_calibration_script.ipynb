{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-plots examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import scikitplot`can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-plots/scikit-plots/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# plot_calibration with examples\n\nAn example showing the :py:func:`~scikitplot.api.metrics.plot_calibration` function\nused by a scikit-learn classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The scikit-plots developers\n# SPDX-License-Identifier: BSD-3-Clause\n\n# run: Python scripts and shows any outputs directly in the notebook.\n# %run ./examples/calibration/plot_calibration_script.py\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_predict\n\nimport numpy as np; np.random.seed(0)  # reproducibility\n# importing pylab or pyplot\nimport matplotlib.pyplot as plt\n\n# Import scikit-plot\nimport scikitplot as sp\n\n# Load the data\nX, y = make_classification(\n  n_samples=100000, \n  n_features=20,\n  n_informative=4,\n  n_redundant=2,\n  n_repeated=0,\n  n_classes=3,\n  n_clusters_per_class=2,\n  random_state=0\n)\nX_train, y_train, X_val, y_val = X[:1000], y[:1000], X[1000:], y[1000:]\n\n# Create an instance of the LogisticRegression\nlr_probas = LogisticRegression(max_iter=int(1e5), random_state=0).fit(X_train, y_train).predict_proba(X_val)\nnb_probas = GaussianNB().fit(X_train, y_train).predict_proba(X_val)\nsvc_scores = LinearSVC().fit(X_train, y_train).decision_function(X_val)\nsvc_isotonic = CalibratedClassifierCV(LinearSVC(), cv=2, method=\"isotonic\").fit(X_train, y_train).predict_proba(X_val)\nsvc_sigmoid = CalibratedClassifierCV(LinearSVC(), cv=2, method=\"sigmoid\").fit(X_train, y_train).predict_proba(X_val)\nrf_probas = RandomForestClassifier(random_state=0).fit(X_train, y_train).predict_proba(X_val)\n\nprobas_dict = {\n  LogisticRegression(): lr_probas,\n  # GaussianNB(): nb_probas,\n  \"LinearSVC() + MinMax\": svc_scores,\n  \"LinearSVC() + Isotonic\": svc_isotonic,\n  \"LinearSVC() + Sigmoid\": svc_sigmoid,\n  # RandomForestClassifier(): rf_probas,\n}\n# Plot!\nfig, ax = plt.subplots(figsize=(12, 6))\nax = sp.metrics.plot_calibration(\n  y_val,\n  y_probas_list=probas_dict.values(),\n  estimator_names=probas_dict.keys(),\n  ax=ax,\n);\n\n# Adjust layout to make sure everything fits\nplt.tight_layout()\n\n# Save the plot with a filename based on the current script's name\n# sp.api._utils.save_plot()\n\n# Display the plot\nplt.show(block=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. admonition:: Interpretation\n\n    Primary Use: Evaluating probabilistic classifiers by comparing predicted probabilities to observed frequencies of the positive class.\n\n    Goal: To assess how well the predicted probabilities align with the actual outcomes, identifying if a model is well-calibrated, overconfident, or underconfident.\n\n    Typical Characteristics:\n\n    - X-axis: Predicted probability (e.g., in bins from 0 to 1).\n    - Y-axis: Observed frequency of the positive class within each bin.\n    - Reference line (diagonal at 45\u00b0): Represents perfect calibration, where predicted probabilities match observed frequencies.\n\n.. tags::\n\n   model-type: classification\n   model-workflow: model evaluation\n   component: fitted model\n   plot-type: line\n   plot-type: calibration plot\n   level: beginner\n   purpose: showcase\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
